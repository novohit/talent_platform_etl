# æ•°æ®ç®¡é“æ’ä»¶ (Data Pipeline Plugin)

è¿™æ˜¯ä¸€ä¸ªå¤æ‚çš„å¤šåŒ…ç»“æ„æ•°æ®å¤„ç†ç®¡é“æ’ä»¶ï¼Œå±•ç¤ºäº†è°ƒåº¦ç³»ç»Ÿæ”¯æŒçš„é«˜çº§æ’ä»¶æ¶æ„ã€‚

## ğŸ—ï¸ æ¶æ„æ¦‚è§ˆ

```
plugins/data_pipeline/
â”œâ”€â”€ utils/              # å·¥å…·åŒ…
â”‚   â”œâ”€â”€ logger.py      # æ—¥å¿—ç®¡ç†
â”‚   â”œâ”€â”€ helpers.py     # è¾…åŠ©å‡½æ•°
â”‚   â””â”€â”€ decorators.py  # è£…é¥°å™¨
â”œâ”€â”€ config/            # é…ç½®åŒ…
â”‚   â””â”€â”€ settings.py    # é…ç½®ç®¡ç†
â”œâ”€â”€ fetchers/          # æ•°æ®è·å–åŒ…
â”‚   â”œâ”€â”€ api_fetcher.py      # APIæ•°æ®è·å–
â”‚   â”œâ”€â”€ database_fetcher.py # æ•°æ®åº“æ•°æ®è·å–
â”‚   â””â”€â”€ file_fetcher.py     # æ–‡ä»¶æ•°æ®è·å–
â”œâ”€â”€ processors/        # æ•°æ®å¤„ç†åŒ…
â”‚   â”œâ”€â”€ data_cleaner.py     # æ•°æ®æ¸…æ´—
â”‚   â”œâ”€â”€ data_transformer.py # æ•°æ®è½¬æ¢
â”‚   â””â”€â”€ data_validator.py   # æ•°æ®éªŒè¯
â”œâ”€â”€ storage/           # æ•°æ®å­˜å‚¨åŒ…
â”‚   â”œâ”€â”€ database_storage.py # æ•°æ®åº“å­˜å‚¨
â”‚   â”œâ”€â”€ file_storage.py     # æ–‡ä»¶å­˜å‚¨
â”‚   â””â”€â”€ cache_storage.py    # ç¼“å­˜å­˜å‚¨
â”œâ”€â”€ main.py            # ä¸»å…¥å£
â”œâ”€â”€ plugin.json        # æ’ä»¶é…ç½®
â””â”€â”€ config.env.example # ç¯å¢ƒå˜é‡ç¤ºä¾‹
```

## âœ¨ ä¸»è¦ç‰¹æ€§

### ğŸ”§ å¤šåŒ…æ¶æ„

- **utils**: æä¾›æ—¥å¿—ã€è¾…åŠ©å‡½æ•°ã€è£…é¥°å™¨ç­‰é€šç”¨å·¥å…·
- **config**: å®Œæ•´çš„é…ç½®ç®¡ç†ç³»ç»Ÿï¼Œæ”¯æŒç¯å¢ƒå˜é‡å’ŒéªŒè¯
- **fetchers**: å¤šæ•°æ®æºè·å–æ”¯æŒï¼ˆAPIã€æ•°æ®åº“ã€æ–‡ä»¶ï¼‰
- **processors**: æ•°æ®å¤„ç†ç®¡é“ï¼ˆæ¸…æ´—ã€è½¬æ¢ã€éªŒè¯ï¼‰
- **storage**: å¤šå­˜å‚¨æ–¹æ¡ˆï¼ˆæ•°æ®åº“ã€æ–‡ä»¶ã€ç¼“å­˜ï¼‰

### ğŸš€ é«˜çº§åŠŸèƒ½

- **å®Œæ•´çš„ ETL æµç¨‹**: è·å– â†’ å¤„ç† â†’ å­˜å‚¨
- **å¤šæ•°æ®æºæ”¯æŒ**: APIã€æ•°æ®åº“ã€æ–‡ä»¶
- **è£…é¥°å™¨æ”¯æŒ**: è®¡æ—¶ã€é‡è¯•ã€ç¼“å­˜ã€é€Ÿç‡é™åˆ¶ç­‰
- **é…ç½®ç®¡ç†**: åˆ†å±‚é…ç½®ï¼Œç¯å¢ƒå˜é‡æ”¯æŒ
- **é”™è¯¯å¤„ç†**: å®Œå–„çš„é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶
- **ç›‘æ§æŒ‡æ ‡**: æ‰§è¡Œç»Ÿè®¡ã€æ€§èƒ½ç›‘æ§
- **å¥åº·æ£€æŸ¥**: ç»„ä»¶çŠ¶æ€ç›‘æ§

## ğŸ¯ æ”¯æŒçš„æ“ä½œ

### 1. å®Œæ•´ç®¡é“ (full_pipeline)

```bash
python -m talent_platform.scheduler_app trigger data_pipeline --operation full_pipeline --source api --endpoint teachers
```

### 2. ä»…æ•°æ®è·å– (fetch_only)

```bash
python -m talent_platform.scheduler_app trigger data_pipeline --operation fetch_only --source database --table teachers
```

### 3. å¥åº·æ£€æŸ¥ (health_check)

```bash
python -m talent_platform.scheduler_app trigger data_pipeline --operation health_check
```

### 4. é…ç½®ä¿¡æ¯ (config_info)

```bash
python -m talent_platform.scheduler_app trigger data_pipeline --operation config_info
```

### 5. ç»Ÿè®¡ä¿¡æ¯ (stats)

```bash
python -m talent_platform.scheduler_app trigger data_pipeline --operation stats
```

## âš™ï¸ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡é…ç½®

å¤åˆ¶ `config.env.example` ä¸º `.env` å¹¶æ ¹æ®éœ€è¦ä¿®æ”¹ï¼š

```bash
# åŸºç¡€é…ç½®
PLUGIN_NAME=data_pipeline
LOG_LEVEL=INFO
DEBUG_MODE=true

# APIé…ç½®
API_BASE_URL=https://api.example.com
API_TIMEOUT=30
API_RETRIES=3

# æ•°æ®åº“é…ç½®
DB_HOST=localhost
DB_NAME=talent_platform
DB_USER=pipeline_user
DB_PASSWORD=your_password

# å¤„ç†é…ç½®
BATCH_SIZE=100
MAX_WORKERS=4
EXECUTION_MODE=sequential
```

### æ“ä½œå‚æ•°

#### full_pipeline å‚æ•°

- `source`: æ•°æ®æºç±»å‹ (api/database/file)
- `endpoint`: API ç«¯ç‚¹ (å½“ source=api æ—¶)
- `table`: æ•°æ®è¡¨å (å½“ source=database æ—¶)
- `file_path`: æ–‡ä»¶è·¯å¾„ (å½“ source=file æ—¶)
- `batch_mode`: æ˜¯å¦å¯ç”¨æ‰¹å¤„ç†æ¨¡å¼

#### fetch_only å‚æ•°

- `source`: æ•°æ®æºç±»å‹ (å¿…éœ€)
- `params`: è¯·æ±‚å‚æ•° (å¯é€‰)

## ğŸ“Š ä½¿ç”¨ç¤ºä¾‹

### 1. API æ•°æ®å¤„ç†

```python
# ä»APIè·å–æ•™å¸ˆæ•°æ®å¹¶å¤„ç†
result = plugin_manager.execute_plugin(
    "data_pipeline",
    operation="full_pipeline",
    source="api",
    endpoint="teachers",
    params={"page": 1, "limit": 50}
)
```

### 2. æ•°æ®åº“æ‰¹é‡å¤„ç†

```python
# ä»æ•°æ®åº“è·å–æ•°æ®å¹¶æ‰¹é‡å¤„ç†
result = plugin_manager.execute_plugin(
    "data_pipeline",
    operation="full_pipeline",
    source="database",
    table="teachers",
    limit=100
)
```

### 3. æ–‡ä»¶æ•°æ®å¤„ç†

```python
# å¤„ç†CSVæ–‡ä»¶æ•°æ®
result = plugin_manager.execute_plugin(
    "data_pipeline",
    operation="full_pipeline",
    source="file",
    file_path="teachers.csv",
    format="csv"
)
```

## ğŸ” ç›‘æ§ä¸è°ƒè¯•

### å¥åº·æ£€æŸ¥

```python
health = plugin_manager.execute_plugin(
    "data_pipeline",
    operation="health_check"
)
print(f"Pipeline status: {health['pipeline_status']}")
```

### æ€§èƒ½ç»Ÿè®¡

```python
stats = plugin_manager.execute_plugin(
    "data_pipeline",
    operation="stats"
)
print(f"Success rate: {stats['success_rate']:.2%}")
print(f"Average execution time: {stats['average_execution_time_formatted']}")
```

## ğŸ”„ è°ƒåº¦ä»»åŠ¡

æ’ä»¶æ”¯æŒé¢„å®šä¹‰çš„è°ƒåº¦ä»»åŠ¡ï¼š

- **daily_teacher_sync**: æ¯æ—¥å‡Œæ™¨ 2 ç‚¹åŒæ­¥æ•™å¸ˆæ•°æ®
- **hourly_health_check**: æ¯å°æ—¶æ‰§è¡Œå¥åº·æ£€æŸ¥

å¯é€šè¿‡è°ƒåº¦ç³»ç»Ÿç®¡ç†ç•Œé¢å¯ç”¨/ç¦ç”¨è¿™äº›ä»»åŠ¡ã€‚

## ğŸ› ï¸ æ‰©å±•å¼€å‘

### æ·»åŠ æ–°çš„æ•°æ®è·å–å™¨

1. åœ¨ `fetchers/` ç›®å½•åˆ›å»ºæ–°çš„è·å–å™¨ç±»
2. ç»§æ‰¿åŸºç¡€æ¥å£å¹¶å®ç° `fetch()` æ–¹æ³•
3. åœ¨ `__init__.py` ä¸­å¯¼å‡ºæ–°ç±»
4. åœ¨ä¸»ç®¡é“ä¸­é›†æˆ

### æ·»åŠ æ–°çš„å¤„ç†å™¨

1. åœ¨ `processors/` ç›®å½•åˆ›å»ºæ–°çš„å¤„ç†å™¨ç±»
2. å®ç°æ•°æ®å¤„ç†é€»è¾‘
3. é›†æˆåˆ°ä¸»å¤„ç†æµç¨‹ä¸­

### è‡ªå®šä¹‰é…ç½®

1. åœ¨ `config/settings.py` ä¸­æ·»åŠ æ–°çš„é…ç½®ç±»
2. æ›´æ–°ç¯å¢ƒå˜é‡è§£æ
3. åœ¨ `plugin.json` ä¸­å£°æ˜æ–°çš„ç¯å¢ƒå˜é‡

## ğŸ“ æ—¥å¿—è¯´æ˜

æ’ä»¶ä½¿ç”¨åˆ†å±‚æ—¥å¿—ç³»ç»Ÿï¼š

- **DEBUG**: è¯¦ç»†çš„æ‰§è¡Œæ­¥éª¤
- **INFO**: å…³é”®æ“ä½œå’Œç»“æœ
- **WARNING**: éè‡´å‘½é—®é¢˜
- **ERROR**: é”™è¯¯å’Œå¼‚å¸¸

æ—¥å¿—æ ¼å¼æ”¯æŒæ ‡å‡†æ ¼å¼å’Œ JSON æ ¼å¼ï¼Œå¯é€šè¿‡ `LOG_FORMAT` ç¯å¢ƒå˜é‡æ§åˆ¶ã€‚

## ğŸ” å®‰å…¨è€ƒè™‘

- æ•°æ®åº“å¯†ç ç­‰æ•æ„Ÿä¿¡æ¯é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®
- æ”¯æŒæ•°æ®éªŒè¯å’Œæ¸…æ´—ï¼Œé˜²æ­¢æ³¨å…¥æ”»å‡»
- é…ç½®éªŒè¯ç¡®ä¿ç³»ç»Ÿå®‰å…¨è¿è¡Œ
- é”™è¯¯ä¿¡æ¯ä¸åŒ…å«æ•æ„Ÿæ•°æ®

---
